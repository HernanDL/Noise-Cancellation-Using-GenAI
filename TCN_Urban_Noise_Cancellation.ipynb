{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmkMdQQSel5B8oiHKW0Rb4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HernanDL/Noise-Cancellation-Using-GenAI/blob/main/TCN_Urban_Noise_Cancellation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TCN-based Urban Noise Prediction and Phase Cancellation\n",
        "\n",
        "This Colab notebook implements a Temporal Convolutional Network (TCN) for predicting and canceling urban noise patterns. It generates synthetic urban noise, trains a TCN model on this data, and evaluates its performance on unseen uploaded WAV files.\n",
        "\n",
        "## Table of Contents:\n",
        "1. **Introduction**\n",
        "2. **Importing Libraries**\n",
        "3. **Define TCN Model Class**\n",
        "4. **Synthetic Urban Noise Generation**\n",
        "5. **Data Preparation**\n",
        "6. **Building the TCN Model**\n",
        "7. **Training the Model**\n",
        "8. **Evaluating the Model**\n",
        "9. **Saving and Loading the Model**\n",
        "10. **Testing on Uploaded WAV File**\n",
        "11. **Conclusion**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Introduction:\n",
        "Urban noise includes sounds such as those from machinery, engines, and constant background hums. This noise spans a wide frequency range, typically from **20 Hz** (low hums) to **20,000 Hz** (high-pitched sounds). Traditional noise cancellation techniques may struggle with such a diverse spectrum, so we explore a TCN model that uses historical context to predict and invert these noises for better cancellation.\n",
        "\n",
        "In this notebook, we'll:\n",
        "- Generate synthetic urban-like noise patterns.\n",
        "- Train a TCN model to predict and invert these noise patterns.\n",
        "- Test the model on both synthetic data and real-world WAV files.\n",
        "- Visualize the model's predictions and listen to the results.\n",
        "\n",
        "## 2. Importing Libraries:\n",
        "The necessary libraries for the TCN model, audio handling, and plotting are imported.\n",
        "\n",
        "\n",
        "## 3. Define TCN Model Class:\n",
        "The `WaveformPredictor` class manages the generation of synthetic noise, the training process, and predictions. It includes:\n",
        "- Parameters for waveform generation, model architecture, and training.\n",
        "- Methods to generate urban-like noise, prepare training data, build the TCN model, and plot results.\n",
        "\n",
        "\n",
        "## 4. Synthetic Urban Noise Generation:\n",
        "Synthetic noise is generated using a combination of random sine and cosine waves to simulate various urban noise patterns (e.g., engines, machinery). Each call to `generate_waveform` creates a unique pattern to encourage model generalization.\n",
        "\n",
        "\n",
        "## 5. Data Preparation:\n",
        "Data is prepared by generating multiple waveforms, segmenting them into sequences, and preparing input-output pairs for training. The output is the inverted phase of the noise, which helps the TCN model learn to predict signals that could cancel out the original noise.\n",
        "\n",
        "\n",
        "## 6. Building the TCN Model:\n",
        "The TCN model is constructed using convolutional layers with dilations for long-range dependencies. It uses the `Conv1D` layers with increasing dilation rates to capture complex temporal patterns.\n",
        "\n",
        "\n",
        "## 7. Training the Model:\n",
        "The model is trained on synthetic waveforms using a low learning rate for stability. Early stopping is used to prevent overfitting.\n",
        "\n",
        "\n",
        "## 8. Evaluating the Model:\n",
        "After training, the model is evaluated on new synthetic noise and the results are visualized. The following plots are generated:\n",
        "- **Input Waveform**: The original test waveform.\n",
        "- **Predicted Waveform**: The TCN model’s prediction.\n",
        "- **Combined Waveform**: The sum of the input and predicted waveforms to evaluate phase cancellation.\n",
        "- **Residual Noise (dB)**: Difference between input and predicted waveforms in decibels.\n",
        "\n",
        "\n",
        "## 9. Saving and Loading the Model:\n",
        "The trained model is saved for future use, allowing users to reload the model without retraining. This is helpful for testing the model with new inputs like WAV files.\n",
        "\n",
        "\n",
        "## 10. Testing on Uploaded WAV File:\n",
        "This section allows users to upload a WAV file, make predictions using the loaded TCN model, and visualize the results.\n",
        "\n",
        "\n",
        "## 11. Conclusion:\n",
        "The TCN model offers a robust approach for modeling and predicting complex noise patterns over time. By leveraging its ability to capture long-term dependencies, it can better predict the inverted phases needed for noise cancellation. While the training can be slow, especially for long sequences, it provides flexibility in handling diverse and non-stationary signals like urban noise."
      ],
      "metadata": {
        "id": "zpQ4CIZ7oyu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtuUqxVsEkqG",
        "outputId": "3579450d-dbbb-4df8-f938-70e3091c639d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU for training.\n",
            "\u001b[1m 32553/137500\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53:15\u001b[0m 30ms/step - loss: 0.0880"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "\n",
        "class WaveformPredictorTCN:\n",
        "    # Parameters for easy tuning\n",
        "    num_training_waves = 100  # Number of waves to use for training\n",
        "    duration = 1.0           # Duration in seconds\n",
        "    sample_rate = 44100      # Samples per second\n",
        "    epochs = 1               # Number of training epochs\n",
        "    learning_rate = 0.0001   # Learning rate for the optimizer\n",
        "    sequence_length = 100    # Number of previous samples to consider for prediction\n",
        "    max_freq = 10000         # Maximum frequency for urban noise generation\n",
        "    batch_size = 32          # Batch size for training\n",
        "\n",
        "    def __init__(self):\n",
        "        self.model = self.build_model()\n",
        "        self.device = self.set_device()\n",
        "\n",
        "    def set_device(self):\n",
        "        if tf.config.list_physical_devices('GPU'):\n",
        "            print(\"Using GPU for training.\")\n",
        "            return 'GPU'\n",
        "        else:\n",
        "            print(\"Using CPU for training.\")\n",
        "            return 'CPU'\n",
        "\n",
        "    def generate_waveform(self):\n",
        "        t = np.linspace(0, self.duration, int(self.sample_rate * self.duration), endpoint=False)\n",
        "        # Generate random urban noise-like signal by combining sine waves with varying amplitudes\n",
        "        frequencies = np.random.uniform(20, self.max_freq, np.random.randint(3, 10))  # Random number of waves\n",
        "        waveform = np.sum([np.random.uniform(0.2, 1.0) * np.sin(2 * np.pi * f * t) for f in frequencies], axis=0)\n",
        "        return waveform / np.max(np.abs(waveform))  # Normalize to [-1, 1]\n",
        "\n",
        "    def prepare_data(self):\n",
        "        input_waveforms = np.array([self.generate_waveform() for _ in range(self.num_training_waves)])\n",
        "\n",
        "        X, y = [], []\n",
        "        for waveform in input_waveforms:\n",
        "            for i in range(len(waveform) - self.sequence_length):\n",
        "                X.append(waveform[i:i + self.sequence_length])\n",
        "                y.append(-waveform[i + self.sequence_length])  # Predict the inverted phase\n",
        "\n",
        "        X = np.array(X).reshape(-1, self.sequence_length, 1)\n",
        "        y = np.array(y)\n",
        "        return X, y\n",
        "\n",
        "    def build_model(self):\n",
        "        input_layer = layers.Input(shape=(self.sequence_length, 1))\n",
        "        # First TCN block\n",
        "        tcn = layers.Conv1D(filters=64, kernel_size=3, padding='causal', activation='relu', dilation_rate=1)(input_layer)\n",
        "        tcn = layers.BatchNormalization()(tcn)\n",
        "        tcn = layers.Conv1D(filters=64, kernel_size=3, padding='causal', activation='relu', dilation_rate=2)(tcn)\n",
        "        tcn = layers.BatchNormalization()(tcn)\n",
        "\n",
        "        # Second TCN block with increased dilation\n",
        "        tcn = layers.Conv1D(filters=64, kernel_size=3, padding='causal', activation='relu', dilation_rate=4)(tcn)\n",
        "        tcn = layers.BatchNormalization()(tcn)\n",
        "\n",
        "        # Flatten and dense layers for output\n",
        "        flatten = layers.Flatten()(tcn)\n",
        "        output_layer = layers.Dense(1)(flatten)\n",
        "\n",
        "        model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "        model.compile(optimizer=Adam(learning_rate=self.learning_rate), loss='mean_squared_error')\n",
        "        return model\n",
        "\n",
        "    def train(self):\n",
        "        X, y = self.prepare_data()\n",
        "        early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "        history = self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=1, callbacks=[early_stopping])\n",
        "        return history\n",
        "\n",
        "    def predict(self, test_waveform):\n",
        "        X_test = []\n",
        "        for i in range(len(test_waveform) - self.sequence_length):\n",
        "            X_test.append(test_waveform[i:i + self.sequence_length])\n",
        "        X_test = np.array(X_test).reshape(len(X_test), self.sequence_length, 1)\n",
        "        predicted_waveform = self.model.predict(X_test)\n",
        "        return predicted_waveform.flatten()  # Ensure it returns a 1D array\n",
        "\n",
        "    def plot_results(self, test_waveform, predicted_waveform, combined_waveform):\n",
        "        time_axis = np.linspace(0, self.duration, int(self.sample_rate * self.duration), endpoint=False)\n",
        "        zoom_duration = 0.05  # 50 ms\n",
        "        zoom_samples = int(self.sample_rate * zoom_duration)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        plt.subplot(5, 1, 1)\n",
        "        plt.title('Input Waveform')\n",
        "        plt.plot(time_axis[:zoom_samples], test_waveform[:zoom_samples], color='blue')\n",
        "        plt.xlim(0, zoom_duration)\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.subplot(5, 1, 2)\n",
        "        plt.title('Predicted Waveform')\n",
        "        plt.plot(time_axis[self.sequence_length:self.sequence_length + zoom_samples], predicted_waveform[:zoom_samples], color='orange')\n",
        "        plt.xlim(0, zoom_duration)\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.subplot(5, 1, 3)\n",
        "        plt.title('Combined Waveform (Input + Predicted)')\n",
        "        plt.plot(time_axis[self.sequence_length:self.sequence_length + zoom_samples], combined_waveform[:zoom_samples], color='green')\n",
        "        plt.xlim(0, zoom_duration)\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Amplitude')\n",
        "\n",
        "        plt.subplot(5, 1, 4)\n",
        "        plt.title('Combined vs Input')\n",
        "        plt.plot(time_axis[self.sequence_length:self.sequence_length + zoom_samples], combined_waveform[:zoom_samples], color='orange', label='Combined')\n",
        "        plt.plot(time_axis[self.sequence_length:self.sequence_length + zoom_samples], test_waveform[self.sequence_length:self.sequence_length + zoom_samples], color='red', label='Input')\n",
        "        plt.xlim(0, zoom_duration)\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.legend()\n",
        "\n",
        "        residuals = combined_waveform[:zoom_samples]\n",
        "        residuals_db = 20 * np.log10(np.abs(residuals) + 1e-10)\n",
        "\n",
        "        plt.subplot(5, 1, 5)\n",
        "        plt.title('Residual Noise (dB)')\n",
        "        plt.plot(time_axis[self.sequence_length:self.sequence_length + zoom_samples], residuals_db, color='red')\n",
        "        plt.xlabel('Time (s)')\n",
        "        plt.ylabel('Residual (dB)')\n",
        "        plt.ylim(-100, 0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, path='waveform_model.h5'):\n",
        "        self.model.save(path)\n",
        "        print(f\"Model saved to {path}\")\n",
        "\n",
        "    def load_model(self, path='waveform_model.h5'):\n",
        "        self.model = models.load_model(path)\n",
        "        print(f\"Model loaded from {path}\")\n",
        "\n",
        "    def test_with_wav(self, wav_path):\n",
        "        test_waveform, _ = librosa.load(wav_path, sr=self.sample_rate)\n",
        "        predicted_waveform = self.predict(test_waveform)\n",
        "        combined_waveform = test_waveform[self.sequence_length:] + predicted_waveform\n",
        "\n",
        "        # Plot results\n",
        "        self.plot_results(test_waveform, predicted_waveform, combined_waveform)\n",
        "\n",
        "        # Provide audio playback\n",
        "        print(\"Test Input Waveform:\")\n",
        "        display(Audio(test_waveform, rate=self.sample_rate))\n",
        "        print(\"Predicted Inverted Waveform:\")\n",
        "        display(Audio(predicted_waveform, rate=self.sample_rate))\n",
        "        print(\"Combined Waveform:\")\n",
        "        display(Audio(combined_waveform, rate=self.sample_rate))\n",
        "\n",
        "    def model_summary(self):\n",
        "        self.model.summary()\n",
        "\n",
        "# Usage\n",
        "predictor_tcn = WaveformPredictorTCN()\n",
        "history = predictor_tcn.train()\n",
        "\n",
        "# Generate a new test waveform for prediction\n",
        "test_waveform = predictor_tcn.generate_waveform()\n",
        "predicted_waveform = predictor_tcn.predict(test_waveform)\n",
        "\n",
        "# Calculate combined waveform\n",
        "combined_waveform = test_waveform[predictor_tcn.sequence_length:] + predicted_waveform\n",
        "\n",
        "# Show model summary\n",
        "predictor_tcn.model_summary()\n",
        "\n",
        "# Plot results\n",
        "predictor_tcn.plot_results(test_waveform, predicted_waveform, combined_waveform)\n",
        "\n",
        "# Provide audio playback\n",
        "print(\"Test Input Waveform:\")\n",
        "display(Audio(test_waveform, rate=predictor_tcn.sample_rate))\n",
        "print(\"Predicted Inverted Waveform:\")\n",
        "display(Audio(predicted_waveform, rate=predictor_tcn.sample_rate))\n",
        "print(\"Combined Waveform:\")\n",
        "display(Audio(combined_waveform, rate=predictor_tcn.sample_rate))\n",
        "\n",
        "# Save the model for later use\n",
        "predictor.save_model('waveform_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f-T06rdlqqjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with a local WAV file\n",
        "predictor.load_model('waveform_model.h5')\n",
        "\n",
        "# Upload WAV file\n",
        "uploaded = files.upload()\n",
        "wav_filename = list(uploaded.keys())[0]\n",
        "\n",
        "predictor.test_with_wav(wav_filename)"
      ],
      "metadata": {
        "id": "hxaCnolHrg53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}